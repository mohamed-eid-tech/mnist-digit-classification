{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries and Set Device\n",
        "# Import necessary libraries and set the random seed and device (GPU if available)\n"
      ],
      "metadata": {
        "id": "AuNPNhTII-zq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gradio as gr\n",
        "import os\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcODao9yJDQW",
        "outputId": "c9885477-4ef9-4514-ee45-80d16abce4b9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define CNN Model for MNIST Classification\n",
        "# A simple CNN with two convolutional layers, dropout, and two fully connected layers\n"
      ],
      "metadata": {
        "id": "5R27Dyb2JK8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "bCKGRgybJLl6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load MNIST Dataset with Data Augmentation\n",
        "# Apply augmentation only on training set, normalize both training and validation data\n"
      ],
      "metadata": {
        "id": "2rjoewZWJSz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mnist_data(batch_size=64):\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    full_dataset = datasets.MNIST('data', train=True, download=True, transform=train_transform)\n",
        "    train_size = int(0.8 * len(full_dataset))\n",
        "    val_size = len(full_dataset) - train_size\n",
        "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "    val_dataset.dataset.transform = val_transform\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader"
      ],
      "metadata": {
        "id": "2sFFamRhJTVS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model with Early Stopping\n",
        "# Save the best model based on validation loss and stop training if no improvement for 'patience' epochs\n"
      ],
      "metadata": {
        "id": "z8aia-niJZFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, epochs=30, learning_rate=0.001, patience=5):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    model.to(device)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * images.size(0)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        accuracy = 100 * correct / total\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f} - Val Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), 'best_model.pth')  # Save best model weights\n",
        "            print(\"Saved best model.\")\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n",
        "\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"Early stopping after {epoch+1} epochs.\")\n",
        "            break\n",
        "\n",
        "    model.load_state_dict(torch.load('best_model.pth'))  # Load best model before returning\n",
        "    return model"
      ],
      "metadata": {
        "id": "0Z8H5W6oJbOm"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess Input Image for Prediction\n",
        "# Convert input from Gradio Sketchpad to normalized tensor suitable for the model\n"
      ],
      "metadata": {
        "id": "oEF1ittSJj3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(input_data):\n",
        "    if isinstance(input_data, dict):\n",
        "        if 'image' in input_data:\n",
        "            image = input_data['image']\n",
        "        elif 'composite' in input_data:\n",
        "            image = input_data['composite']\n",
        "        else:\n",
        "            raise ValueError(\"Dictionary input missing image data\")\n",
        "    elif isinstance(input_data, np.ndarray):\n",
        "        image = input_data\n",
        "    else:\n",
        "        try:\n",
        "            image = np.array(input_data)\n",
        "        except:\n",
        "            raise ValueError(f\"Unsupported input type: {type(input_data)}\")\n",
        "\n",
        "    if image.ndim == 3:\n",
        "        if image.shape[2] == 4:\n",
        "            image = image[..., :3]\n",
        "        image = np.mean(image, axis=2)  # Convert to grayscale by averaging channels\n",
        "\n",
        "    image = 255 - image  # Invert colors: background black, digit white\n",
        "\n",
        "    image_tensor = transforms.functional.to_tensor(image).unsqueeze(0)\n",
        "    image_tensor = transforms.functional.resize(image_tensor, (28, 28))\n",
        "    image_tensor = transforms.functional.normalize(image_tensor, (0.1307,), (0.3081,))\n",
        "    return image_tensor"
      ],
      "metadata": {
        "id": "ayHRgnwtJkc6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot Prediction Probabilities Bar Chart\n",
        "# Visualize the model's output probabilities for digits 0-9\n"
      ],
      "metadata": {
        "id": "9KAxrJhOJnNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_probabilities(probabilities):\n",
        "    fig, ax = plt.subplots()\n",
        "    bars = ax.bar(range(10), probabilities)\n",
        "    ax.set_xlabel('Digit')\n",
        "    ax.set_ylabel('Probability')\n",
        "    ax.set_title('Prediction Probabilities')\n",
        "    ax.set_xticks(range(10))\n",
        "    ax.set_ylim(0, 1)\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                f'{height:.2f}',\n",
        "                ha='center', va='bottom')\n",
        "    return fig"
      ],
      "metadata": {
        "id": "CGw9Zb06JpNH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction Function for Gradio Interface\n",
        "# Processes input, predicts digit, and returns predicted digit and probability plot"
      ],
      "metadata": {
        "id": "Xz-ynVgnJr62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_digit(input_data):\n",
        "    try:\n",
        "        input_tensor = preprocess_image(input_data).to(device)\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            probabilities = torch.softmax(output, dim=1).cpu().numpy()[0]\n",
        "        predicted_digit = int(np.argmax(probabilities))\n",
        "        prob_plot = plot_probabilities(probabilities)\n",
        "        return predicted_digit, prob_plot\n",
        "    except Exception as e:\n",
        "        print(f\"Error during prediction: {str(e)}\")\n",
        "        return \"Error\", None"
      ],
      "metadata": {
        "id": "ybURa_DhJuXh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data and Prepare DataLoaders\n",
        "# Load MNIST dataset with augmentation and split into training and validation loaders\n"
      ],
      "metadata": {
        "id": "JlvkwHYwJz4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading data...\")\n",
        "train_loader, val_loader = load_mnist_data(batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grvrxHT8J0Z7",
        "outputId": "7b8ee143-b878-4283-de68-f48c0532b6dd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create or Load Model\n",
        "# Initialize the CNN model, load saved weights if available, otherwise train the model\n"
      ],
      "metadata": {
        "id": "XCKKq5EyKPNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Creating model...\")\n",
        "model = MNISTClassifier()\n",
        "\n",
        "if os.path.exists('best_model.pth'):\n",
        "    model.load_state_dict(torch.load('best_model.pth'))\n",
        "    model.to(device)\n",
        "    print(\"Loaded saved model.\")\n",
        "else:\n",
        "    print(\"Training model...\")\n",
        "    model = train_model(model, train_loader, val_loader, epochs=30, patience=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM1lkJMHKP_O",
        "outputId": "56c14fd0-1fcd-48c1-cd07-e17fa3895ce0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating model...\n",
            "Loaded saved model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup Gradio Interface\n",
        "# Create a simple UI for drawing digits and displaying predictions and probability plots\n"
      ],
      "metadata": {
        "id": "e0521rQpKi8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# MNIST Digit Recognition\")\n",
        "    gr.Markdown(\"Draw a digit (0-9) in the box below and see the model's prediction.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        sketchpad = gr.Sketchpad(label=\"Draw Digit\", image_mode=\"L\", type=\"numpy\")\n",
        "        with gr.Column():\n",
        "            label = gr.Label(label=\"Predicted Digit\")\n",
        "            plot = gr.Plot(label=\"Prediction Probabilities\")\n",
        "\n",
        "    sketchpad.change(fn=predict_digit, inputs=sketchpad, outputs=[label, plot])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "eg7f0EQ3KkKm",
        "outputId": "38601a66-ac7c-4bc1-bcaf-2447c889952f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c0c09b0cd564dc7c8e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c0c09b0cd564dc7c8e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}